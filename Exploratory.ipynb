{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "    import sklearn\n",
    "from WikiCatUtils import (\n",
    "    Cache,\n",
    "    read_categories,\n",
    "    get_fullpath,\n",
    "    resample_to_equal)\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "import numpy as np\n",
    "\n",
    "if not exists('./test'):                                                               \n",
    "    mkdir('./test')                                                                    \n",
    "categories_to_download = read_categories(get_fullpath('example_cats.txt'))                 \n",
    "cache = Cache(get_fullpath('test/cache'), verbosity=0)                            \n",
    "for category_uri in categories_to_download:                                                  \n",
    "    cache.loadCategory(category_uri, only_use_cached=True)# maxlinks=100)\n",
    "\n",
    "\n",
    "dset, label_map = cache.get_dataset(0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val': 214, 'train': 635, 'test': 215}\n",
      "1064\n",
      "\t0\t1\t2\t3\t4\t5\t6\n",
      "val\t0.06\t0.03\t0.10\t0.05\t0.03\t0.64\t0.10\n",
      "train\t0.06\t0.03\t0.10\t0.05\t0.03\t0.64\t0.10\n",
      "test\t0.06\t0.03\t0.10\t0.05\t0.03\t0.63\t0.10\n",
      "{0: 'Category:Medical devices', 1: 'Category:Organs (anatomy)', 2: 'Category:Congenital disorders', 3: 'Category:Machine learning algorithms', 4: 'Category:Cancer', 5: 'Category:Rare diseases', 6: 'Category:Infectious diseases'}\n"
     ]
    }
   ],
   "source": [
    "# dataset statistics\n",
    "print({split:len(dset[split][0]) for split in dset})\n",
    "reverse_label_map = {label_map[category]:category for category in label_map}\n",
    "indices = reverse_label_map.keys()\n",
    "print(len(cache.contents))\n",
    "print(\"\\t%s\" % ('\\t'.join(map(str,indices))))\n",
    "for split in dset:\n",
    "    category_percentages = []\n",
    "    for category_ind in indices:\n",
    "        category_percentages.append(dset[split][1].count(category_ind)\n",
    "                                    / len(dset[split][1]))\n",
    "    print(\"%s\\t%s\" % (split, '\\t'.join(map(lambda x: \"%0.2f\" % x, category_percentages))))\n",
    "\n",
    "print(reverse_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(635, 10939)\n"
     ]
    }
   ],
   "source": [
    "# this is extremely unbalanced, but we'll see how well it does despite that\n",
    "# let's try BoW first as a baseline\n",
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "punct_matcher = re.compile(r'[{}]+'.format(re.escape(punctuation)))\n",
    "space_matcher = re.compile(r'\\s+')\n",
    "def tokenize(article, lower=False):\n",
    "    # instead of tokenizing by anything fancy we'll just separate by spaces\n",
    "    # and remove punctuation / quotes / hyphens\n",
    "    stripped = article.rstrip().lstrip()\n",
    "    no_punct = re.sub(punct_matcher, '', stripped)\n",
    "    tokenized = re.split(space_matcher, no_punct)\n",
    "    if lower:\n",
    "        tokenized = list(map(lambda x: x.lower(), tokenized))\n",
    "    return tokenized\n",
    "\n",
    "def make_vocab(articles, lower=False):\n",
    "    vocab = {}\n",
    "    for article in articles:\n",
    "        tokenized_article = tokenize(article, lower=lower)\n",
    "        for word in tokenized_article:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = 1\n",
    "            else:\n",
    "                vocab[word] += 1\n",
    "    return vocab\n",
    "\n",
    "def convert_classes(labels):\n",
    "    # most ml packages expect multiclass labels to be one-hot encoded\n",
    "    n_classes = max(labels) + 1\n",
    "    label_indices = list(zip(*[(ind, class_ind) for ind, class_ind in enumerate(labels)]))\n",
    "    label_mat = np.zeros((len(labels), n_classes))\n",
    "    label_mat[label_indices] = 1\n",
    "    return label_mat\n",
    "\n",
    "\n",
    "#train_vocab = make_vocab(dset['train'][0])\n",
    "#print(len(train_vocab))\n",
    "class BoW_transformer:\n",
    "    def __init__(self, minsample=5, tfidf_weights=False, normalize=True):\n",
    "        self.use_tfidf = tfidf_weights    \n",
    "        self.minsample = minsample\n",
    "        self.normalize = normalize\n",
    "        \n",
    "    def get_idf(self, articles):\n",
    "        # for every word in the vocab, get its inverse doc freq\n",
    "        self.idf = np.zeros((1,self.vocab_size))\n",
    "        vocab_appears_in = {word:np.zeros(len(articles), dtype=np.int) \n",
    "                            for word in self.lookup}\n",
    "        for ind, article in enumerate(articles):\n",
    "            for word in tokenize(article, lower=True):\n",
    "                if word in self.lookup:\n",
    "                    vocab_appears_in[word][ind] = 1\n",
    "        for word in self.lookup:\n",
    "            self.idf[:,self.lookup[word]] = np.log(1 + len(articles) / np.sum(\n",
    "                                                vocab_appears_in[word]))\n",
    "            \n",
    "    def fit(self, articles, labels):\n",
    "        # figure out the vocab and tfidf stuff\n",
    "        self.vocab = make_vocab(articles)\n",
    "        vocab_sorted = sorted(self.vocab.keys())\n",
    "        vocab_minsampled = list(filter(lambda x: self.vocab[x] >= self.minsample, \n",
    "                                       vocab_sorted))\n",
    "        self.lookup = {word:ind for ind, word in enumerate(vocab_minsampled)}\n",
    "        self.vocab_size = len(self.lookup)\n",
    "        if self.use_tfidf:\n",
    "            self.get_idf(articles)\n",
    "        if self.normalize:\n",
    "            # determine normalization constants\n",
    "            self.normalize = False\n",
    "            transformed_articles = self.transform(articles)\n",
    "            self.normalize = True\n",
    "            self.maxes = np.max(transformed_articles, axis=0)\n",
    "            self.mins = np.min(transformed_articles, axis=0)\n",
    "        return self # needed for pipeline\n",
    "    \n",
    "    def transform_single(self, tokenized_article):\n",
    "        bowvec = np.zeros((1,self.vocab_size), dtype=np.float32)\n",
    "        for word in tokenized_article:\n",
    "            if word in self.lookup:\n",
    "                word_ind = self.lookup[word]\n",
    "                if self.use_tfidf:\n",
    "                    bowvec[:,word_ind] += 1\n",
    "                else:\n",
    "                    bowvec[:,word_ind] = 1\n",
    "        if self.use_tfidf:\n",
    "            # implement the log-scaled frequency\n",
    "            bowvec = np.log(1 + bowvec)\n",
    "            bowvec *= self.idf\n",
    "        if self.normalize:\n",
    "            bowvec = (bowvec - self.mins) / (self.maxes - self.mins)\n",
    "            bowvec[np.where(np.isnan(bowvec))] = 0.5 # shouldn't happen but just in case\n",
    "        return bowvec\n",
    "    \n",
    "    def transform(self, articles):\n",
    "        return np.vstack([self.transform_single(tokenize(article)) \n",
    "                          for article in articles])\n",
    "                \n",
    "bow_maker = BoW_transformer()\n",
    "bow_maker.fit(dset['train'][0], dset['train'][1])\n",
    "train_bow = bow_maker.transform(dset['train'][0])\n",
    "train_labels = convert_classes(dset['train'][1])\n",
    "print(train_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(tokenize(dset['train'][0][0]))\n",
    "#print(dset['train'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "bow_linear = LogisticRegression()\n",
    "bow_linear.fit(train_bow, dset['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[ 36  18  63  31  20 406  61]\n"
     ]
    }
   ],
   "source": [
    "print(bow_linear.score(train_bow, dset['train'][1]))\n",
    "# This result (~100% accuracy) shows the inherent issue with having a ton of features\n",
    "# and very little data -- obviously we're well beyond LogisticRegression's VC dimension\n",
    "print(np.histogram(bow_linear.predict(train_bow), bins=train_labels.shape[1])[0])\n",
    "# this is real bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9   5   9  11   1 157  22]\n",
      "[ 12   6  21  11   7 136  21]\n",
      "0.85046728972\n"
     ]
    }
   ],
   "source": [
    "# We can very easily see the overfitting here\n",
    "val_bow = bow_maker.transform(dset['val'][0])\n",
    "val_labels = convert_classes(dset['val'][1])\n",
    "\n",
    "print(np.histogram(bow_linear.predict(val_bow), bins=val_labels.shape[1])[0])\n",
    "print(np.histogram(np.argmax(val_labels, axis=1), bins=val_labels.shape[1])[0])\n",
    "print(bow_linear.score(val_bow, dset['val'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828325491375\n",
      "0.0341412878191\n"
     ]
    }
   ],
   "source": [
    "# Despite the overfitting it's worth noting that it performs rather well\n",
    "# However it should also be noted that it is going to be heavily biased towards the \n",
    "# 'Infectious Diseases' class since it has far more articles\n",
    "# Let's see how this holds up under cross validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cv_scores = cross_val_score(LogisticRegression(), train_bow, dset['train'][1], cv=5)\n",
    "print(np.average(cv_scores))\n",
    "print(np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So it seems to be getting ~84% accuracy pretty regularly. We'll see if we can improve\n",
    "# it using TF-IDF weights -- however we need to be careful since we need to learn these \n",
    "# weights only on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:57: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:90: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tfidf_maker = BoW_transformer(tfidf_weights=True)\n",
    "bow_tfidf_maker.fit(dset['train'][0], dset['train'][1])\n",
    "train_bow_tfidf = bow_tfidf_maker.transform(dset['train'][0])\n",
    "\n",
    "\n",
    "bow_linear_tfidf = LogisticRegression()\n",
    "bow_linear_tfidf.fit(train_bow_tfidf, dset['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99527559055118109"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_linear_tfidf.score(train_bow_tfidf, dset['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:90: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78971962616822433"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it doesn't seem like TF-IDF helps, but let's verify that with cross validation\n",
    "val_bow_tfidf = bow_tfidf_maker.transform(dset['val'][0])\n",
    "bow_linear_tfidf.score(val_bow_tfidf, dset['val'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:57: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:90: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow_tfidf', <__main__.BoW_transformer object at 0x7f54551abfd0>), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to be sure we'll make a simple pipeliner that can take the representer and learner\n",
    "# in one so we can try out CV on this\n",
    "from sklearn.pipeline import Pipeline\n",
    "# minsample =~ 5 seems to do the best\n",
    "bow_tfidf = BoW_transformer(tfidf_weights=True, minsample=5)\n",
    "bow_logreg = LogisticRegression()\n",
    "bow_tfidf_logreg = Pipeline([('bow_tfidf', bow_tfidf), ('logreg', bow_logreg)])\n",
    "bow_tfidf_logreg.fit(dset['train'][0], dset['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:57: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:90: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:57: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:90: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:57: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:90: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:57: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:90: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:57: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/usr/lib/python3.5/site-packages/ipykernel/__main__.py:90: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79201788784\n",
      "0.0222314405877\n"
     ]
    }
   ],
   "source": [
    "# Well it does worse\n",
    "cv_scores = cross_val_score(bow_tfidf_logreg, dset['train'][0], dset['train'][1], cv=5)\n",
    "print(np.average(cv_scores))\n",
    "print(np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of words in val vocab that are also in train vocab: 60.17\n"
     ]
    }
   ],
   "source": [
    "# I'm willing to bet that a large part of this is the difference in vocabulary between \n",
    "# any given split of the data. To test this\n",
    "train_vocab = make_vocab(dset['train'][0])\n",
    "val_vocab = make_vocab(dset['val'][0])\n",
    "print(\"Percentage of words in val vocab that are also in train vocab: %0.2f\" % \n",
    "      (100*len([val_word for val_word in val_vocab.keys() if val_word in train_vocab]) / \n",
    "       len(val_vocab)))\n",
    "# Thus ~35% of the time a word was processed in the validation data, it was not in the\n",
    "# the training vocab & therefore was skipped, which is pretty awful -- especially when\n",
    "# we have a strong prior belief that words unique to an article and their latent meaning\n",
    "# will strongly indicate the category of the article\n",
    "\n",
    "# We could alleviate this problem at first by using the entire dataset at hand to learn a\n",
    "# vocabulary, but as we can see below the size of this would be prohibitive (at least 400k)\n",
    "# We could do something like a sparse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GloVe classifier\n",
    "# Averaging co-occurence based word embeddings is a pretty powerful baseline \n",
    "# in my experience, so let's try it out here using GloVe embeddings\n",
    "# Conveniently Jeffrey Pennington has trained GloVe embeddings on a 2014 dump of Wikipedia\n",
    "# which is probably fine for this task. In the interests of expediency I'm not going to \n",
    "# train them myself (it will take a long time for lower quality embeddings), but use the\n",
    "# pretrained embeddings from here: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# Since this is on the entirety of Wikipedia, we can safely assume that there is some\n",
    "# data snooping based on learning these cooccurence statistics\n",
    "# in addition, this means that it has a larger vocabulary to work with than BoW, alle\n",
    "# WikiCatBuild will automatically download these into the cache if they're not there\n",
    "import codecs\n",
    "def glove_read(dimsize, articles):\n",
    "    fn = './glove.6B.%dd.txt' % dimsize\n",
    "    if not exists(fn):\n",
    "        print(\"GloVe vectors of size %d aren't there\" % dimsize)\n",
    "        return None\n",
    "    # we're going to ignore words that aren't in the articles given to reduce memory usage\n",
    "    vocab_dataset = make_vocab(articles)\n",
    "    vocab_ret = {}\n",
    "    with codecs.open(fn, 'r', 'utf8') as f:\n",
    "        for line in f:\n",
    "            split_line = str(line).rstrip().split(' ')\n",
    "            word = split_line[0]\n",
    "            if word in vocab_dataset:\n",
    "                vocab_ret[word] = np.array(list(map(float, split_line[1:])))\n",
    "    return vocab_ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class WordEmbedding_transform:\n",
    "    def __init__(self, vocab, dim, use_tfidf_weights=False, normalize=True):\n",
    "        # Assume vocab is the mapping of word to ndarray vector\n",
    "        self.vocab = vocab\n",
    "        self.dim = dim\n",
    "        self.use_tfidf = use_tfidf_weights\n",
    "        self.normalize = normalize\n",
    "        \n",
    "    def get_idf(self, articles):\n",
    "        # for every word in the vocab, get its inverse doc freq\n",
    "        # essentially this way we avoid divide by zero since if we hit\n",
    "        # the default we're saying that the word as far as we know only\n",
    "        # exists in the document we're evaluating\n",
    "        self.idf = defaultdict(lambda: np.log(1 + len(articles)))\n",
    "        #local_vocab = make_vocab(articles)\n",
    "        vocab_appears_in = defaultdict(lambda: np.zeros(len(articles)))\n",
    "        for ind, article in enumerate(articles):\n",
    "            for word in tokenize(article):\n",
    "                if word in self.vocab:\n",
    "                    vocab_appears_in[word][ind] = 1\n",
    "        for word in vocab_appears_in:\n",
    "            self.idf[word] = np.log(1 + len(articles) / \n",
    "                                     (np.sum(vocab_appears_in[word])))\n",
    "            # this should never hit a divide by zero\n",
    "    \n",
    "    def fit(self, articles, labels):\n",
    "        # calculate idf \n",
    "        if self.use_tfidf:\n",
    "            self.get_idf(articles)\n",
    "        if self.normalize:\n",
    "            self.normalize = False\n",
    "            transformed_articles = self.transform(articles)\n",
    "            self.normalize = True\n",
    "            self.maxes = np.max(transformed_articles, axis=0)\n",
    "            self.mins = np.min(transformed_articles, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, articles):\n",
    "        vecs = []\n",
    "        oov = 0\n",
    "        total_words = 0\n",
    "        for article in articles:\n",
    "            avg_vec = np.zeros((1,self.dim))\n",
    "            # compute the tfidf weights, req 2 passes unfortunately\n",
    "            tokenized_article = list(filter(lambda x: x in self.vocab, tokenize(article)))\n",
    "            word_weight = defaultdict(lambda: 1/len(tokenized_article))\n",
    "            # word_weight defaults to 1/n for non-tfidf case\n",
    "            if self.use_tfidf:\n",
    "                for word in tokenized_article:\n",
    "                    word_weight[word] = word_weight[word] + int(word in word_weight)\n",
    "                for word in word_weight:\n",
    "                    word_weight[word] = np.log(1 + word_weight[word])\n",
    "                    word_weight[word] *= self.idf[word]\n",
    "            for word in tokenized_article:\n",
    "                avg_vec += word_weight[word] * self.vocab[word].reshape(1,self.dim)\n",
    "            if self.normalize:\n",
    "                avg_vec = (avg_vec - self.mins) / (self.maxes - self.mins)\n",
    "                avg_vec[np.where(np.isnan(avg_vec))] = 0.5 # shouldn't happen but just in case\n",
    "            vecs.append(avg_vec)\n",
    "        \n",
    "        return np.vstack(vecs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50: Training acc: 0.802\n",
      "50: CV acc: 0.777 w/std 0.015\n",
      "50: TFIDF Training acc: 0.666\n",
      "50: TFIDF CV acc: 0.662 w/std 0.023\n",
      "100: Training acc: 0.843\n",
      "100: CV acc: 0.805 w/std 0.022\n",
      "100: TFIDF Training acc: 0.683\n",
      "100: TFIDF CV acc: 0.676 w/std 0.023\n",
      "200: Training acc: 0.880\n",
      "200: CV acc: 0.819 w/std 0.034\n",
      "200: TFIDF Training acc: 0.698\n",
      "200: TFIDF CV acc: 0.686 w/std 0.020\n",
      "300: Training acc: 0.906\n",
      "300: CV acc: 0.832 w/std 0.033\n",
      "300: TFIDF Training acc: 0.715\n",
      "300: TFIDF CV acc: 0.692 w/std 0.021\n"
     ]
    }
   ],
   "source": [
    "# Let's determine the best dimensionality to use by cross validation\n",
    "from itertools import chain\n",
    "all_articles = list(chain(dset['train'][0], dset['val'][0], dset['test'][0]))\n",
    "for dim in [50,100,200,300]:\n",
    "    glove_vecs = glove_read(dim, all_articles)    \n",
    "    embedder = WordEmbedding_transform(glove_vecs, dim, normalize=True)\n",
    "    embedder.fit(dset['train'][0], dset['train'][1])\n",
    "    train = embedder.transform(dset['train'][0])        \n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(train, dset['train'][1])\n",
    "    \n",
    "\n",
    "    print(\"%d: Training acc: %0.3f\" % (dim, logreg.score(train, dset['train'][1])))\n",
    "    \n",
    "    cv_scores = cross_val_score(logreg, train, dset['train'][1], n_jobs=8, cv=8)\n",
    "\n",
    "    print(\"%d: CV acc: %0.3f w/std %0.3f\" % (dim, \n",
    "                                             np.average(cv_scores), \n",
    "                                             np.std(cv_scores)))\n",
    "    \n",
    "    tfidf_emb = WordEmbedding_transform(glove_vecs, dim, use_tfidf_weights=True, normalize=True)\n",
    "    tfidf_logreg = Pipeline([('tfidf_emb', tfidf_emb), ('logreg', logreg)])\n",
    "    tfidf_logreg.fit(dset['train'][0], dset['train'][1])\n",
    "    tfidf_cv_scores = cross_val_score(tfidf_logreg,\n",
    "                                      dset['train'][0],\n",
    "                                      dset['train'][1], cv=8)\n",
    "\n",
    "    print(\"%d: TFIDF Training acc: %0.3f\" % (dim, tfidf_logreg.score(dset['train'][0],\n",
    "                                                                     dset['train'][1])))\n",
    "    print(\"%d: TFIDF CV acc: %0.3f w/std %0.3f\" % (dim, \n",
    "                                             np.average(tfidf_cv_scores), \n",
    "                                             np.std(tfidf_cv_scores)))\n",
    "    #val = embedder.transform(dset['val'][0])\n",
    "    #print(\"Validation acc: %0.3f\" % logreg.score(val, dset['val'][1]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957480314961\n",
      "0.757009345794\n"
     ]
    }
   ],
   "source": [
    "# I've re-run the above several times with different splits of the dataset and found (mostly)\n",
    "# that 200 is the best dimensionality, normalization hurts performance but helps control\n",
    "# overfitting when using TF-IDF, though this normalization is super necessary for good\n",
    "# performance without TF-IDF.\n",
    "\n",
    "# Initially my thoughts were that TF-IDF weights would help, but they seem to cause heavy\n",
    "# overfitting. My theory is that only learning the TF-IDF weights on the training data is\n",
    "# the cause of this, and in retrospect this doesn't really seem justified since I'm using\n",
    "# GloVe embeddings that were trained on the entire Wikipedia.\n",
    "# Instead of determining TF-IDF weights from the whole Wikipedia, let's just use the entire\n",
    "# dataset (or in this case training + val)\n",
    "tfidf_g200 = glove_read(200, all_articles)\n",
    "tfidf_emb = WordEmbedding_transform(tfidf_g200, 200, normalize=False, use_tfidf_weights=True)\n",
    "tfidf_emb.fit(list(chain(dset['train'][0], dset['val'][0])),\n",
    "              list(chain(dset['train'][1], dset['val'][1])))\n",
    "tfidf_train = tfidf_emb.transform(dset['train'][0])\n",
    "tfidf_val = tfidf_emb.transform(dset['val'][0])\n",
    "tfidf_logreg = LogisticRegression(C=0.125)\n",
    "tfidf_logreg.fit(tfidf_train, dset['train'][1])\n",
    "print(tfidf_logreg.score(tfidf_train, dset['train'][1]))\n",
    "print(tfidf_logreg.score(tfidf_val, dset['val'][1]))\n",
    "# It would appear that the overfitting isn't helped by learning the TF-IDF weights from the\n",
    "# whole corpus, but normalizing the results does help prevent overfitting (at the cost of\n",
    "# reducing performance overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating <class 'sklearn.svm.classes.LinearSVC'>\n",
      "\tTraining accuracy: 0.92\n",
      "\tCV score: 0.80 (+/- 0.01)\n",
      "\tVal score: 0.80\n",
      "Evaluating <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\tTraining accuracy: 0.99\n",
      "\tCV score: 0.77 (+/- 0.01)\n",
      "\tVal score: 0.75\n",
      "Evaluating <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "\tTraining accuracy: 0.84\n",
      "\tCV score: 0.80 (+/- 0.01)\n",
      "\tVal score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# I think based solely on this limited and most likely incomplete analysis I'll go with\n",
    "# keeping the representation at averaging 200-dimensional pre-trained GloVe vectors, and\n",
    "# normalizing them.\n",
    "\n",
    "# Now let's try a few different classifiers to see what makes sense\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# For the initial analysis the time expenditure that would be needed to find the best\n",
    "# hyperparameters is a bit out of scope, so we'll use the sklearn defaults\n",
    "\n",
    "best_emb = WordEmbedding_transform(tfidf_g200, 200, normalize=True)\n",
    "best_emb.fit(dset['train'][0], dset['train'][1])\n",
    "train_data = best_emb.transform(dset['train'][0])\n",
    "val_data = best_emb.transform(dset['val'][0])\n",
    "emb_svm = LinearSVC(class_weight='auto')\n",
    "emb_rf = RandomForestClassifier(class_weight='auto')\n",
    "emb_knn = KNeighborsClassifier()\n",
    "emb_lr = LogisticRegression(class_weight='auto')\n",
    "\n",
    "classifiers = [emb_svm, emb_rf, emb_knn]#, emb_lr]\n",
    "for classifier in classifiers:\n",
    "    print(\"Evaluating %s\" % classifier.__class__)\n",
    "    classifier.fit(train_data, dset['train'][1])\n",
    "    train_score = classifier.score(train_data, dset['train'][1])\n",
    "    cv_scores = cross_val_score(classifier, train_data, dset['train'][1], cv=10)\n",
    "    cv_avg = np.average(cv_scores)\n",
    "    cv_std = np.std(cv_scores)\n",
    "    val_score = classifier.score(val_data, dset['val'][1])\n",
    "    print(\"\\tTraining accuracy: %0.2f\" % train_score)\n",
    "    print(\"\\tCV score: %0.2f (+/- %0.2f)\" % (cv_avg, cv_std/2))\n",
    "    print(\"\\tVal score: %0.2f\" % val_score)\n",
    "\n",
    "# So interestingly the SVM overfits very heavily but gets a better validation accuracy\n",
    "# for it, though the high variance in its CV scores are concerning. RF overfits very\n",
    "# heavily, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.85\n",
      "CV score: 0.82 (+/- 0.01)\n",
      "Val score: 0.78\n",
      "[ 2.34172859  2.58260842  1.36911414  2.51661591  2.28602989  1.34230777\n",
      "  2.26507416]\n"
     ]
    }
   ],
   "source": [
    "# So K-NN actually seems to be the most stable / overfit the least, however I won't use it\n",
    "# because it's not at all scalable. Besides that, it appears that LogisticRegression is \n",
    "# the way to go. \n",
    "# Notably this is using the 'One-v-Rest' strategy for training (I tried multinomial, \n",
    "# results were significantly worse).\n",
    "\n",
    "# Let's try regularizing it now w/L2 regularization and looking over the possible C values\n",
    "# Powers of 10 shows that between C = 1e-1 and C=1e0 works\n",
    "# Binary search down to 0.125\n",
    "# Ultimately it looks like C = 0.125 gives the best C score w/minimal overfitting\n",
    "emb_lr.C = 0.125\n",
    "emb_lr.fit(train_data, dset['train'][1])\n",
    "train_score = emb_lr.score(train_data, dset['train'][1])\n",
    "cv_scores = cross_val_score(emb_lr, train_data, dset['train'][1], cv=10)\n",
    "cv_avg = np.average(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "val_score = classifier.score(val_data, dset['val'][1])\n",
    "print(\"Training accuracy: %0.2f\" % train_score)\n",
    "print(\"CV score: %0.2f (+/- %0.2f)\" % (cv_avg, cv_std/2))\n",
    "print(\"Val score: %0.2f\" % val_score)\n",
    "\n",
    "print(np.linalg.norm(emb_lr.coef_, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0049886622043486279"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
