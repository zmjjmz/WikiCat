{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "from WikiCatUtils import (\n",
    "    get_fullpath,         \n",
    "    read_categories,      \n",
    "    load_obj,             \n",
    "    ArticlePage,          \n",
    "    CategoryPage,         \n",
    "    Cache,                \n",
    "    Representer,          \n",
    "    Model,                \n",
    ")                       \n",
    "from os.path import join\n",
    "\n",
    "\n",
    "# Analyses to run:\n",
    "# Generalization to pages in existing categories (already done through CV, report results)\n",
    "# See which categories are close to each other (t-SNE), class centroids\n",
    "# See which features (read: words) are most important to the category:\n",
    "# - Chi2\n",
    "# See which parts of the vector correspond to certain categories (rough idea really since\n",
    "# the embeddings aren't very interpretable, will just have to use the weights for each cat)\n",
    "# How many words need to be changed to get the classifier to change category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/zj1992/work/interviews/enlitic/WikiCat/test/repr.pkl\n",
      "Transforming 635 articles\n",
      "25532 words were OOV out of 584288 total\n",
      "Transforming 214 articles\n",
      "8592 words were OOV out of 207902 total\n",
      "Transforming 215 articles\n",
      "11601 words were OOV out of 252389 total\n",
      "Loading model from /home/zj1992/work/interviews/enlitic/WikiCat/test/model.pkl\n",
      "Train\tVal\tTest\tCV\n",
      "0.84\t0.83\t0.84\t0.83 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "# First one: CV score on training data\n",
    "# This is reported by WikiCatBuild but I'll put it here for posterity\n",
    "root_dir = get_fullpath('test')\n",
    "model_fn = join(root_dir, 'model.pkl')                                                                                            \n",
    "repr_fn = join(root_dir, 'repr.pkl')                                                                                              \n",
    "cache_dir = join(root_dir, 'cache')                                                                                               \n",
    "                                                                                                                                  \n",
    "categories_to_download = read_categories(get_fullpath('example_cats.txt'))                                                      \n",
    "cache = Cache(cache_dir, verbosity=0)                                                                                \n",
    "for category_uri in categories_to_download:                                                                                       \n",
    "    cache.loadCategory(category_uri, only_use_cached=True)                                     \n",
    "                                                                                                                                                                                                                            \n",
    "dset, label_map = cache.get_dataset(0.6, 0.2, 0.2)                                                                                \n",
    "\n",
    "embedder = load_obj(repr_fn)                                                                                                       \n",
    "dset_represented = {}                                                                                                             \n",
    "dset_represented['train'] = (embedder.transform(dset['train'][0]),                                                         \n",
    "                             dset['train'][1])                                                                                    \n",
    "                                                                                                                                  \n",
    "                                                                                                                                  \n",
    "dset_represented['val'] = (embedder.transform(dset['val'][0]),                                                                 \n",
    "                           dset['val'][1])                                                                                        \n",
    "dset_represented['test'] = (embedder.transform(dset['test'][0]),                                                               \n",
    "                           dset['test'][1])                                                                                       \n",
    "                                                                                                                                  \n",
    "# Train model                                                                                                                     \n",
    "model = load_obj(model_fn)                                                                                        \n",
    "                                                                                                                                                                                                                                           \n",
    "model.evaluate(dset_represented)                                                                                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14277353, -0.15465414, -0.36658715, ..., -0.43852336,\n",
       "        -0.42457534, -0.35973273],\n",
       "       [-0.33760859, -0.41119968, -0.32590514, ..., -0.28084811,\n",
       "        -0.6976327 , -0.15303147],\n",
       "       [-0.3080735 , -0.39475969, -0.53543338, ..., -0.40311579,\n",
       "        -0.54484574, -0.36034577],\n",
       "       ..., \n",
       "       [-0.28637095, -0.4187067 , -0.32807543, ..., -0.46420241,\n",
       "        -0.74663737, -0.31676948],\n",
       "       [-0.20481569, -0.27913714, -0.33465707, ..., -0.51932695,\n",
       "        -0.19324101, -0.31733537],\n",
       "       [-0.29237702, -0.64740952, -0.57896501, ..., -0.3784513 ,\n",
       "        -1.        , -0.18198898]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_represented['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
